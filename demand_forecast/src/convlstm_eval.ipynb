{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3264899/1248253995.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('convlstm_5_02.pth'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from convlstm import ConvLSTM  # 假设 ConvLSTM 定义在 convlstm.py 文件中\n",
    "DATABASE_URL = \"postgresql://zhongtai:zt123!@localhost/harbintrips\"\n",
    "\n",
    "def get_pgdb():\n",
    "    return psycopg2.connect(DATABASE_URL)\n",
    "    \n",
    "# 模型参数\n",
    "input_channels = 2  # 一个通道用于历史打车数据，一个通道用于人口密度分布数据\n",
    "hidden_dim = [16, 32]  # 每层的隐藏状态通道数\n",
    "kernel_size = (3, 3)\n",
    "num_layers = 2\n",
    "batch_first = True\n",
    "bias = True\n",
    "return_all_layers = False\n",
    "\n",
    "# 初始化 ConvLSTM 模型\n",
    "model = ConvLSTM(input_dim=input_channels,\n",
    "                 hidden_dim=hidden_dim,\n",
    "                 kernel_size=kernel_size,\n",
    "                 num_layers=num_layers,\n",
    "                 batch_first=batch_first,\n",
    "                 bias=bias,\n",
    "                 return_all_layers=return_all_layers)\n",
    "\n",
    "# 加载保存的模型权重\n",
    "model.load_state_dict(torch.load('convlstm_5_02.pth'))\n",
    "\n",
    "# Check for CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 从数据库加载一个时间步的数据\n",
    "def load_single_time_step(dayid: int, time_index: int):\n",
    "    conn = get_pgdb()\n",
    "    query = \"SELECT dayid, lat_index, lon_index, time_index, ppdensity, trip_count FROM forecast_dataset WHERE dayid = %s and time_index = %s\"\n",
    "    data = pd.read_sql(query, conn, params=(dayid, time_index,))\n",
    "    conn.close()\n",
    "    return data\n",
    "\n",
    "def prepare_single_time_step_data(data):\n",
    "    array_32x21_demand = np.zeros((32, 21), dtype=int)\n",
    "    array_32x21_pp = np.zeros((32, 21), dtype=int)\n",
    "    for point in data.itertuples():\n",
    "        array_32x21_demand[point.lon_index - 52, point.lat_index - 32] = point.trip_count\n",
    "        array_32x21_pp[point.lon_index - 52, point.lat_index - 32] = point.ppdensity\n",
    "    single_time_step_data = [array_32x21_demand.tolist(), array_32x21_pp.tolist()]\n",
    "    return single_time_step_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3264899/1248253995.py:43: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, conn, params=(dayid, time_index,))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 进行预测\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 20\u001b[0m     layer_output_list, last_state_list \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     21\u001b[0m     output \u001b[38;5;241m=\u001b[39m layer_output_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# 获取最后一层的输出\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# 提取打车需求的通道（假设打车需求是第一个通道）\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/Python/backend/demand_forecast/src/convlstm.py:141\u001b[0m, in \u001b[0;36mConvLSTM.forward\u001b[0;34m(self, input_tensor, hidden_state)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mlast_state_list, layer_output\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# if not self.batch_first:\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m#     # (t, b, c, h, w) -> (b, t, c, h, w)\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m#     input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m b, _, _, h, w \u001b[38;5;241m=\u001b[39m input_tensor\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Implement stateful ConvLSTM\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from convlstm import ConvLSTM\n",
    "# 加载一个时间步的数据\n",
    "dayid = 7\n",
    "time_index = 0\n",
    "data = load_single_time_step(dayid, time_index)\n",
    "single_time_step_data = prepare_single_time_step_data(data)\n",
    "\n",
    "# 将数据转换为 PyTorch 张量，并增加批次维度和时间步维度\n",
    "inputs = torch.tensor([single_time_step_data], dtype=torch.float32).to(device)\n",
    "\n",
    "# 进行预测\n",
    "with torch.no_grad():\n",
    "    layer_output_list, last_state_list = model(inputs)\n",
    "    output = layer_output_list[-1]  # 获取最后一层的输出\n",
    "    \n",
    "    # 提取打车需求的通道（假设打车需求是第一个通道）\n",
    "    output = output[:, :, 0, :, :]  # 提取第一个通道\n",
    "\n",
    "    # 打印预测结果\n",
    "    print(\"Predicted Output shape:\", output.shape)\n",
    "    print(\"Predicted Output:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
